{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Logistic Regression Model\n",
        "## Mammography Dataset - Baseline Model with StandardScaler Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().absolute().parent / 'src'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "\n",
        "from data_processing.data_loader import load_mammography_data\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the mammography dataset\n",
        "X, y = load_mammography_data()\n",
        "\n",
        "# Split into training and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATA LOADED AND SPLIT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Test set:     {X_test.shape[0]:,} samples\")\n",
        "print(f\"Features:     {X_train.shape[1]} features\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Pipeline with StandardScaler and Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a pipeline with StandardScaler and LogisticRegression\n",
        "# StandardScaler normalizes features (mean=0, std=1)\n",
        "# LogisticRegression with class_weight='balanced' to handle imbalanced data\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced'  # Handle class imbalance\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PIPELINE CREATED\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Pipeline steps:\")\n",
        "for step_name, step in pipeline.steps:\n",
        "    print(f\"  - {step_name}: {type(step).__name__}\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model on training data\n",
        "print(\"Training baseline Logistic Regression model...\")\n",
        "pipeline.fit(X_train, y_train)\n",
        "print(\"âœ… Model training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Make Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred_proba = pipeline.predict_proba(X_test)\n",
        "\n",
        "print(\"Predictions generated for test set.\")\n",
        "print(f\"Predicted classes: {np.unique(y_pred)}\")\n",
        "print(f\"Prediction probabilities shape: {y_pred_proba.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL EVALUATION RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'METRIC':<30s} {'VALUE':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Accuracy':<30s} {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix in a formatted way\n",
        "print(\"=\" * 70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nConfusion Matrix (Raw Counts):\")\n",
        "print(f\"{'':<20s} {'Predicted Benign':<20s} {'Predicted Malignant':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Actual Benign':<20s} {cm[0, 0]:<20d} {cm[0, 1]:<20d}\")\n",
        "print(f\"{'Actual Malignant':<20s} {cm[1, 0]:<20d} {cm[1, 1]:<20d}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Calculate percentages\n",
        "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "print(\"\\nConfusion Matrix (Percentages):\")\n",
        "print(f\"{'':<20s} {'Predicted Benign':<20s} {'Predicted Malignant':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Actual Benign':<20s} {cm_percent[0, 0]:<20.2f}% {cm_percent[0, 1]:<20.2f}%\")\n",
        "print(f\"{'Actual Malignant':<20s} {cm_percent[1, 0]:<20.2f}% {cm_percent[1, 1]:<20.2f}%\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Raw counts\n",
        "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])\n",
        "disp1.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
        "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "# Plot 2: Normalized percentages\n",
        "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=['Benign', 'Malignant'])\n",
        "disp2.plot(ax=axes[1], cmap='Blues', values_format='.2f')\n",
        "axes[1].set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "plt.suptitle('Baseline Logistic Regression - Confusion Matrix', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print key metrics from confusion matrix\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONFUSION MATRIX METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"True Negatives (TN):  {tn:>6d}  (Correctly predicted Benign)\")\n",
        "print(f\"False Positives (FP): {fp:>6d}  (Predicted Malignant, actually Benign)\")\n",
        "print(f\"False Negatives (FN): {fn:>6d}  (Predicted Benign, actually Malignant)\")\n",
        "print(f\"True Positives (TP):   {tp:>6d}  (Correctly predicted Malignant)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification report\n",
        "class_report = classification_report(\n",
        "    y_test, \n",
        "    y_pred, \n",
        "    target_names=['Benign', 'Malignant'],\n",
        "    output_dict=True\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nPer-Class Metrics:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Class':<15s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support':<12s}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for class_name in ['Benign', 'Malignant']:\n",
        "    metrics = class_report[class_name]\n",
        "    print(f\"{class_name:<15s} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} \"\n",
        "          f\"{metrics['f1-score']:<12.4f} {int(metrics['support']):<12d}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Accuracy':<15s} {'':<12s} {'':<12s} {class_report['accuracy']:<12.4f} \"\n",
        "      f\"{int(class_report['macro avg']['support']):<12d}\")\n",
        "print(f\"{'Macro Avg':<15s} {class_report['macro avg']['precision']:<12.4f} \"\n",
        "      f\"{class_report['macro avg']['recall']:<12.4f} {class_report['macro avg']['f1-score']:<12.4f} \"\n",
        "      f\"{int(class_report['macro avg']['support']):<12d}\")\n",
        "print(f\"{'Weighted Avg':<15s} {class_report['weighted avg']['precision']:<12.4f} \"\n",
        "      f\"{class_report['weighted avg']['recall']:<12.4f} {class_report['weighted avg']['f1-score']:<12.4f} \"\n",
        "      f\"{int(class_report['weighted avg']['support']):<12d}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary\n",
        "\n",
        "**Baseline Model Performance:**\n",
        "- **Model**: Logistic Regression with StandardScaler pipeline\n",
        "- **Training**: Trained on 80% of the data with stratified sampling\n",
        "- **Evaluation**: Tested on 20% of the data\n",
        "\n",
        "**Key Observations:**\n",
        "- This baseline model provides a starting point for comparison\n",
        "- The model uses `class_weight='balanced'` to handle class imbalance\n",
        "- StandardScaler normalizes features for better model performance\n",
        "- Further improvements can be made using techniques like SMOTE, ADASYN, or other algorithms\n",
        "\n",
        "**Next Steps:**\n",
        "- Try different algorithms (Random Forest, SVM, etc.)\n",
        "- Apply resampling techniques (SMOTE, ADASYN)\n",
        "- Optimize hyperparameters\n",
        "- Use cross-validation for more robust evaluation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
