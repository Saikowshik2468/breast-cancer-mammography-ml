{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMOTE + Logistic Regression Model\n",
        "## Mammography Dataset - Imbalanced-Learn Pipeline with SMOTE Oversampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.append(str(Path().absolute().parent / 'src'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_score\n",
        ")\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from data_processing.data_loader import load_mammography_data\n",
        "\n",
        "# Set style for plots\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Split Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the mammography dataset\n",
        "X, y = load_mammography_data()\n",
        "\n",
        "# Split into training and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATA LOADED AND SPLIT\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"Test set:     {X_test.shape[0]:,} samples\")\n",
        "print(f\"Features:     {X_train.shape[1]} features\")\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"  Class {cls}: {count:,} samples ({count/len(y_train)*100:.2f}%)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Imbalanced-Learn Pipeline with SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an imbalanced-learn pipeline with:\n",
        "# 1. StandardScaler - Normalize features\n",
        "# 2. SMOTE - Oversample minority class (malignant)\n",
        "# 3. LogisticRegression - Classifier with balanced class weights\n",
        "\n",
        "pipeline = ImbPipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', LogisticRegression(\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced'\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"IMBALANCED-LEARN PIPELINE CREATED\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Pipeline steps:\")\n",
        "for step_name, step in pipeline.steps:\n",
        "    print(f\"  - {step_name}: {type(step).__name__}\")\n",
        "print(\"\\nNote: SMOTE will oversample the minority class during training\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model on training data\n",
        "# SMOTE will automatically oversample the minority class during fit\n",
        "print(\"Training model with SMOTE oversampling...\")\n",
        "print(\"This may take a moment as SMOTE generates synthetic samples...\")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Check the resampled training data size after SMOTE\n",
        "X_resampled, y_resampled = pipeline.named_steps['smote'].fit_resample(\n",
        "    pipeline.named_steps['scaler'].transform(X_train), \n",
        "    y_train\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Model training completed!\")\n",
        "print(f\"\\nOriginal training set size: {len(y_train):,} samples\")\n",
        "print(f\"After SMOTE resampling:      {len(y_resampled):,} samples\")\n",
        "print(f\"\\nResampled class distribution:\")\n",
        "unique, counts = np.unique(y_resampled, return_counts=True)\n",
        "for cls, count in zip(unique, counts):\n",
        "    print(f\"  Class {cls}: {count:,} samples ({count/len(y_resampled)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Make Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "# Note: SMOTE is only applied during training, not during prediction\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred_proba = pipeline.predict_proba(X_test)\n",
        "\n",
        "print(\"Predictions generated for test set.\")\n",
        "print(f\"Predicted classes: {np.unique(y_pred)}\")\n",
        "print(f\"Prediction probabilities shape: {y_pred_proba.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print confusion matrix in a formatted way\n",
        "print(\"=\" * 70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nConfusion Matrix (Raw Counts):\")\n",
        "print(f\"{'':<20s} {'Predicted Benign':<20s} {'Predicted Malignant':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Actual Benign':<20s} {cm[0, 0]:<20d} {cm[0, 1]:<20d}\")\n",
        "print(f\"{'Actual Malignant':<20s} {cm[1, 0]:<20d} {cm[1, 1]:<20d}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Calculate percentages\n",
        "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "print(\"\\nConfusion Matrix (Percentages):\")\n",
        "print(f\"{'':<20s} {'Predicted Benign':<20s} {'Predicted Malignant':<20s}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Actual Benign':<20s} {cm_percent[0, 0]:<20.2f}% {cm_percent[0, 1]:<20.2f}%\")\n",
        "print(f\"{'Actual Malignant':<20s} {cm_percent[1, 0]:<20.2f}% {cm_percent[1, 1]:<20.2f}%\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Raw counts\n",
        "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])\n",
        "disp1.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
        "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "# Plot 2: Normalized percentages\n",
        "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_percent, display_labels=['Benign', 'Malignant'])\n",
        "disp2.plot(ax=axes[1], cmap='Blues', values_format='.2f')\n",
        "axes[1].set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold', pad=10)\n",
        "\n",
        "plt.suptitle('SMOTE + Logistic Regression - Confusion Matrix', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print key metrics from confusion matrix\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONFUSION MATRIX METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"True Negatives (TN):  {tn:>6d}  (Correctly predicted Benign)\")\n",
        "print(f\"False Positives (FP): {fp:>6d}  (Predicted Malignant, actually Benign)\")\n",
        "print(f\"False Negatives (FN): {fn:>6d}  (Predicted Benign, actually Malignant)\")\n",
        "print(f\"True Positives (TP):   {tp:>6d}  (Correctly predicted Malignant)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate classification report\n",
        "class_report = classification_report(\n",
        "    y_test, \n",
        "    y_pred, \n",
        "    target_names=['Benign', 'Malignant'],\n",
        "    output_dict=True\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nPer-Class Metrics:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Class':<15s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support':<12s}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for class_name in ['Benign', 'Malignant']:\n",
        "    metrics = class_report[class_name]\n",
        "    print(f\"{class_name:<15s} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} \"\n",
        "          f\"{metrics['f1-score']:<12.4f} {int(metrics['support']):<12d}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Accuracy':<15s} {'':<12s} {'':<12s} {class_report['accuracy']:<12.4f} \"\n",
        "      f\"{int(class_report['macro avg']['support']):<12d}\")\n",
        "print(f\"{'Macro Avg':<15s} {class_report['macro avg']['precision']:<12.4f} \"\n",
        "      f\"{class_report['macro avg']['recall']:<12.4f} {class_report['macro avg']['f1-score']:<12.4f} \"\n",
        "      f\"{int(class_report['macro avg']['support']):<12d}\")\n",
        "print(f\"{'Weighted Avg':<15s} {class_report['weighted avg']['precision']:<12.4f} \"\n",
        "      f\"{class_report['weighted avg']['recall']:<12.4f} {class_report['weighted avg']['f1-score']:<12.4f} \"\n",
        "      f\"{int(class_report['weighted avg']['support']):<12d}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate recall and F1-score specifically for the malignant class (class 1)\n",
        "malignant_recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "malignant_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "# Also get precision for context\n",
        "malignant_precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MALIGNANT CLASS (Class 1) METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'Metric':<20s} {'Value':<15s} {'Interpretation'}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Recall (Sensitivity)':<20s} {malignant_recall:<15.4f} \"\n",
        "      f\"({malignant_recall*100:.2f}% of malignant cases correctly identified)\")\n",
        "print(f\"{'Precision':<20s} {malignant_precision:<15.4f} \"\n",
        "      f\"({malignant_precision*100:.2f}% of predicted malignant are actually malignant)\")\n",
        "print(f\"{'F1-Score':<20s} {malignant_f1:<15.4f} \"\n",
        "      f\"(Harmonic mean of precision and recall)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Additional context\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MALIGNANT CLASS PERFORMANCE BREAKDOWN\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"True Positives (TP):  {tp:>6d}  - Correctly identified malignant cases\")\n",
        "print(f\"False Negatives (FN): {fn:>6d}  - Missed malignant cases (Type II error)\")\n",
        "print(f\"False Positives (FP): {fp:>6d}  - Incorrectly flagged as malignant\")\n",
        "print(f\"\\nRecall = TP / (TP + FN) = {tp} / ({tp} + {fn}) = {malignant_recall:.4f}\")\n",
        "print(f\"F1-Score = 2 × (Precision × Recall) / (Precision + Recall) = {malignant_f1:.4f}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Visualize key metrics\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "metrics_names = ['Recall', 'Precision', 'F1-Score']\n",
        "metrics_values = [malignant_recall, malignant_precision, malignant_f1]\n",
        "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "\n",
        "bars = ax.bar(metrics_names, metrics_values, color=colors, edgecolor='black', linewidth=1.5)\n",
        "ax.set_ylim([0, 1.1])\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Malignant Class Performance Metrics', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, value in zip(bars, metrics_values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "            f'{value:.4f}\\n({value*100:.2f}%)',\n",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary\n",
        "\n",
        "**SMOTE + Logistic Regression Model Performance:**\n",
        "- **Pipeline**: StandardScaler → SMOTE → LogisticRegression\n",
        "- **SMOTE**: Oversamples the minority class (malignant) to balance the dataset\n",
        "- **Training**: SMOTE applied only during training, not on test set\n",
        "- **Evaluation**: Tested on original (unresampled) test set\n",
        "\n",
        "**Key Metrics for Malignant Class:**\n",
        "- **Recall**: Measures how many malignant cases were correctly identified\n",
        "- **F1-Score**: Balanced metric combining precision and recall\n",
        "- **Precision**: Measures accuracy of malignant predictions\n",
        "\n",
        "**Advantages of SMOTE:**\n",
        "- Addresses class imbalance by creating synthetic minority samples\n",
        "- Helps the model learn better decision boundaries\n",
        "- Can improve recall for the minority class\n",
        "- Works well with Logistic Regression\n",
        "\n",
        "**Next Steps:**\n",
        "- Compare with baseline model (without SMOTE)\n",
        "- Try ADASYN as an alternative to SMOTE\n",
        "- Experiment with different SMOTE parameters (k_neighbors)\n",
        "- Use cross-validation for more robust evaluation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
